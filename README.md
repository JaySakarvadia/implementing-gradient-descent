# implementing-gradient-descent

Implementing Gradient Descent from scratch for Linear Regression using synthetic data


Gradient Descent, a pivotal optimization algorithm, is instrumental in machine/deep learning for its capability to minimize functions. It achieves this by iteratively moving towards the direction of the steepest descent, thereby locating a local minimum. This algorithm is particularly crucial in determining the optimal parameters that minimize a loss function during model training.

By creating synthetic data with a predefined linear relationship, I was able to observe and verify the parameters deduced by the algorithm through iterative processes, ensuring they aligned with the established data relationship. This was my way of sanity-checking.

Future work includes adding functionality to minimize a user-inputted function (rather than one hardcoded in) using SymPi.
